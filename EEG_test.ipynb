{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import load_dataset_EEG\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils import save_plot_with_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\n",
    "    \"AFF1h\", \"F7\", \"FC5\", \"C3\", \"T7\", \"TP9\", \"Pz\", \"P3\", \"P7\", \"O1\", \"O2\", \"P8\", \"P4\", \"TP10\", \"Cz\", \"C4\", \"T8\", \"FC6\", \"FCz\", \"F8\", \"AFF2h\", \"GSR\", \"EKG\", \"arousal_score\", \"valence_score\"]\n",
    "\n",
    "file = '/Users/calebjonesshibu/Desktop/tom/derived/draft_2023_06_05_11/eeg/exp_2022_10_04_09/leopard_affective_individual_physio_task.csv'\n",
    "df = pd.read_csv(file)\n",
    "imac = os.path.basename(file).split('_')[0]\n",
    "df.drop(columns=['unix_time', 'task_time', 'task_monotonic_time', 'task_human_readable_time', 'task_subject_id', 'seconds_since_start', 'human_readable_time', imac, 'task_index', 'experiment_id'], inplace=True)\n",
    "if 'task_Unnamed: 0' in df.columns:\n",
    "    df.drop(columns='task_Unnamed: 0', inplace=True)\n",
    "\n",
    "df.loc[df['task_event_type'].isin(['intermediate_selection','show_cross_screen', 'show_image', 'show_rating_screen']), ['task_arousal_score', 'task_valence_score']] = np.nan\n",
    "df[['task_image_path', 'task_arousal_score', 'task_valence_score', 'task_event_type']] = df[['task_image_path', 'task_arousal_score', 'task_valence_score', 'task_event_type']].fillna(method='bfill')\n",
    "df.drop(columns=['task_image_path', 'task_event_type'], inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.columns = [None] * len(df.columns)\n",
    "\n",
    "df = df.set_axis(headers, axis=1)\n",
    "df_EEG = df.iloc[:, :23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=21, n_times=89100\n",
      "    Range : 0 ... 89099 =      0.000 ...   178.198 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "ignore_channels = ['AUX_GSR', 'AUX_EKG']\n",
    "channel_names = df_EEG.columns[:21].to_list()\n",
    "channel_types = ['eeg' if ch not in ignore_channels else 'misc' for ch in channel_names]\n",
    "\n",
    "info = mne.create_info(ch_names=channel_names, sfreq=500, ch_types=channel_types)\n",
    "montage = mne.channels.make_standard_montage('standard_1005')\n",
    "info.set_montage(montage)\n",
    "raw = mne.io.RawArray(np.array(df_EEG.iloc[:, :21]).T, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 4 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 4.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 5.00 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 8 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 8.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 9.00 Hz)\n",
      "- Filter length: 825 samples (1.650 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 14 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 14.00 Hz\n",
      "- Upper transition bandwidth: 3.50 Hz (-6 dB cutoff frequency: 15.75 Hz)\n",
      "- Filter length: 825 samples (1.650 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 14 - 31 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 14.00\n",
      "- Lower transition bandwidth: 3.50 Hz (-6 dB cutoff frequency: 12.25 Hz)\n",
      "- Upper passband edge: 31.00 Hz\n",
      "- Upper transition bandwidth: 7.75 Hz (-6 dB cutoff frequency: 34.88 Hz)\n",
      "- Filter length: 473 samples (0.946 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 31 - 50 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 31.00\n",
      "- Lower transition bandwidth: 7.75 Hz (-6 dB cutoff frequency: 27.12 Hz)\n",
      "- Upper passband edge: 50.00 Hz\n",
      "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
      "- Filter length: 213 samples (0.426 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "frequency_bands = {\n",
    "            'delta': (1, 4),\n",
    "            'theta': (4, 8),\n",
    "            'alpha': (8, 14),\n",
    "            'beta': (14, 31),\n",
    "            'gamma': (31, 50)\n",
    "        }\n",
    "filtered_band_data_dict = {}\n",
    "for band_name, (l_freq, h_freq) in frequency_bands.items():\n",
    "    filtered_band_data = raw.copy().filter(l_freq=l_freq, h_freq=h_freq, skip_by_annotation='edge', picks=['eeg'])\n",
    "    filtered_band_data_dict[band_name] = filtered_band_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'delta': <RawArray | 21 x 89100 (178.2 s), ~14.3 MB, data loaded>,\n",
       " 'theta': <RawArray | 21 x 89100 (178.2 s), ~14.3 MB, data loaded>,\n",
       " 'alpha': <RawArray | 21 x 89100 (178.2 s), ~14.3 MB, data loaded>,\n",
       " 'beta': <RawArray | 21 x 89100 (178.2 s), ~14.3 MB, data loaded>,\n",
       " 'gamma': <RawArray | 21 x 89100 (178.2 s), ~14.3 MB, data loaded>}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_band_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = pd.DataFrame(filtered_band_data_dict['beta'].get_data().T)\n",
    "data['arousal_score'] = df['arousal_score'].values\n",
    "data['valence_score'] = df['valence_score'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_LSTM_Affective_Individual_Task_EEG(path, hidden_size, num_epochs, batch_size, learning_rate):\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    output_folder = 'output'\n",
    "    if not os.path.exists(output_folder):\n",
    "        try:\n",
    "            os.makedirs(output_folder)\n",
    "        except OSError as e:\n",
    "            print(f\"Error creating output folder: {e}\")\n",
    "            return\n",
    "        \n",
    "    # Load dataset\n",
    "    merged_df = data #load_dataset_EEG(path)\n",
    "\n",
    "    # Check if CUDA is available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Preprocess data\n",
    "    features = merged_df.iloc[:, :-2].values\n",
    "    arousal_score = LabelEncoder().fit_transform(merged_df.iloc[:, -2] + 2)  # Mapping -2 -> 0, -1 -> 1, 0 -> 2, 1 -> 3, 2 -> 4\n",
    "    valence_score = LabelEncoder().fit_transform(merged_df.iloc[:, -1] + 2)  # Same mapping for valence_score\n",
    "    targets = list(zip(arousal_score, valence_score))\n",
    "\n",
    "    # Hyperparameters\n",
    "    input_size = features.shape[1]\n",
    "    num_classes = 5  # Classes representing -2, -1, 0, 1, 2\n",
    "    num_folds = 5\n",
    "\n",
    "    # Create DataLoaders\n",
    "    dataset = TensorDataset(torch.tensor(features).float().to(device), torch.tensor(targets).long().to(device))\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Define model\n",
    "    class LSTM(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, num_classes):\n",
    "            super(LSTM, self).__init__()\n",
    "            self.hidden_size = hidden_size\n",
    "            self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "            self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            out, _ = self.lstm(x)\n",
    "            out = self.fc(out[:, -1, :])\n",
    "            return out\n",
    "\n",
    "    # Initialize model, loss, and optimizer\n",
    "    model = LSTM(input_size, hidden_size, num_classes).to(device)  # Move the model to the GPU\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    fold_losses = []\n",
    "    fold_accuracies = []\n",
    "\n",
    "    for fold, (train_indices, test_indices) in enumerate(kfold.split(dataset)):\n",
    "        print(f\"Fold {fold+1}/{num_folds}\")\n",
    "\n",
    "        # Split data into train and test sets for the current fold\n",
    "        train_data = Subset(dataset, train_indices)\n",
    "        test_data = Subset(dataset, test_indices)\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "            for i, (inputs, targets) in enumerate(progress_bar):\n",
    "                inputs = inputs.view(-1, 1, input_size)\n",
    "                targets_arousal = targets[:, 0]\n",
    "                targets_valence = targets[:, 1]\n",
    "\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                loss_arousal = criterion(outputs, targets_arousal)\n",
    "                loss_valence = criterion(outputs, targets_valence)\n",
    "\n",
    "                loss = loss_arousal + loss_valence  # Total loss\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        fold_losses.append(loss.item())\n",
    "        print(f\"Loss for Fold {fold+1}: {fold_losses[-1]}\")\n",
    "\n",
    "        # Testing\n",
    "        model.eval()\n",
    "        correct_arousal, correct_valence = 0, 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs = inputs.view(-1, 1, input_size)\n",
    "                targets_arousal = targets[:, 0]\n",
    "                targets_valence = targets[:, 1]\n",
    "\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                _, predicted_arousal = torch.max(outputs.data, 1)\n",
    "                _, predicted_valence = torch.max(outputs.data, 1)\n",
    "\n",
    "                total += targets.size(0)\n",
    "                correct_arousal += (predicted_arousal == targets_arousal).sum().item()\n",
    "                correct_valence += (predicted_valence == targets_valence).sum().item()\n",
    "\n",
    "        accuracy_arousal = 100 * correct_arousal / total\n",
    "        accuracy_valence = 100 * correct_valence / total\n",
    "        fold_accuracies.append((accuracy_arousal, accuracy_valence))\n",
    "\n",
    "    # Print average accuracy and standard deviation across folds\n",
    "    arousal_accuracies, valence_accuracies = zip(*fold_accuracies)\n",
    "    print(\"Average accuracy for arousal_score:\", np.mean(arousal_accuracies))\n",
    "    print(\"Standard deviation for arousal_score:\", np.std(arousal_accuracies))\n",
    "    print(\"Average accuracy for valence_score:\", np.mean(valence_accuracies))\n",
    "    print(\"Standard deviation for valence_score:\", np.std(valence_accuracies))\n",
    "\n",
    "    # Print the average loss per fold.\n",
    "    print(f\"Average loss per fold: {np.mean(fold_losses)}\")\n",
    "    print(f\"Standard deviation of loss per fold: {np.std(fold_losses)}\")\n",
    "\n",
    "    arousal_cm = confusion_matrix(targets_arousal.cpu(), predicted_arousal.cpu())\n",
    "    valence_cm = confusion_matrix(targets_valence.cpu(), predicted_valence.cpu())\n",
    "    # Define the class names (assuming -2 to 2 for arousal and valence scores)\n",
    "    class_names = [-2, -1, 0, 1, 2]\n",
    "\n",
    "    # Plotting confusion matrix for arousal\n",
    "    plt.figure(figsize=(20, 14))\n",
    "    sns.heatmap(arousal_cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
    "    plt.title(f'EEG: Confusion Matrix for Arousal\\nHidden Size: {hidden_size}, Batch Size: {batch_size}, Learning Rate: {learning_rate}, Epochs: {num_epochs}, Accuracy: {accuracy_arousal:.2f}%, std: {np.std(arousal_accuracies):.2f}%, loss: {np.mean(fold_losses):.2f}, std: {np.std(fold_losses):.2f}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    save_plot_with_timestamp(plt, 'confusion_matrix_arousal', output_folder)\n",
    "\n",
    "    # Plotting confusion matrix for valence\n",
    "    plt.figure(figsize=(20, 14))\n",
    "    sns.heatmap(valence_cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
    "    plt.title(f'EEG: Confusion Matrix for Valence\\nHidden Size: {hidden_size}, Batch Size: {batch_size}, Learning Rate: {learning_rate}, Epochs: {num_epochs}, Accuracy: {accuracy_valence:.2f}%, std: {np.std(valence_accuracies):.2f}%, loss: {np.mean(fold_losses):.2f}, std: {np.std(fold_losses):.2f}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    save_plot_with_timestamp(plt, 'confusion_matrix_valence', output_folder)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser(\n",
    "#         description=\"Post experiment script for xdf to csv file conversion\"\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--p\", required=True, help=\"Path to the directory with the derived affective task data\"\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--hidden_size\", type=int, default=256, help=\"Hidden size for the LSTM model\"\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--num_epochs\", type=int, default=100, help=\"Number of epochs for training\"\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--batch_size\", type=int, default=256, help=\"Batch size for training\"\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--learning_rate\", type=float, default=0.001, help=\"Learning rate for optimizer\"\n",
    "#     )\n",
    "\n",
    "#     args = parser.parse_args()\n",
    "#     path = args.p\n",
    "#     hidden_size = args.hidden_size\n",
    "#     num_epochs = args.num_epochs\n",
    "#     batch_size = args.batch_size\n",
    "#     learning_rate = args.learning_rate\n",
    "\n",
    "#     sys.exit(classify_LSTM_Affective_Individual_Task_EEG(path, hidden_size, num_epochs, batch_size, learning_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: 21\n",
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 279/279 [00:02<00:00, 119.05it/s, loss=2.66]\n",
      "Epoch 2/2: 100%|██████████| 279/279 [00:02<00:00, 120.87it/s, loss=2.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for Fold 1: 2.5571048259735107\n",
      "Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 279/279 [00:02<00:00, 118.88it/s, loss=2.59]\n",
      "Epoch 2/2: 100%|██████████| 279/279 [00:02<00:00, 128.63it/s, loss=2.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for Fold 2: 2.512396812438965\n",
      "Fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 279/279 [00:02<00:00, 117.37it/s, loss=2.61]\n",
      "Epoch 2/2: 100%|██████████| 279/279 [00:02<00:00, 128.49it/s, loss=2.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for Fold 3: 2.561903953552246\n",
      "Fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 279/279 [00:02<00:00, 129.72it/s, loss=2.52]\n",
      "Epoch 2/2: 100%|██████████| 279/279 [00:02<00:00, 131.29it/s, loss=2.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for Fold 4: 2.6559977531433105\n",
      "Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 279/279 [00:02<00:00, 127.64it/s, loss=2.63]\n",
      "Epoch 2/2: 100%|██████████| 279/279 [00:02<00:00, 120.83it/s, loss=2.65]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for Fold 5: 2.647057294845581\n",
      "Average accuracy for arousal_score: 35.87542087542088\n",
      "Standard deviation for arousal_score: 0.3162116331817881\n",
      "Average accuracy for valence_score: 34.931537598204265\n",
      "Standard deviation for valence_score: 0.3651883854351852\n",
      "Average loss per fold: 2.5868921279907227\n",
      "Standard deviation of loss per fold: 0.05559978236070936\n"
     ]
    }
   ],
   "source": [
    "classify_LSTM_Affective_Individual_Task_EEG(_, 120, 2, 256, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/calebjonesshibu/Desktop/tom/derived/draft_2023_06_05_11/eeg/exp_2022_10_04_09/leopard_affective_individual_physio_task.csv'\n",
    "df = pd.read_csv(file)\n",
    "imac = os.path.basename(file).split('_')[0]\n",
    "df.drop(columns=['task_image_path', 'task_valence_score', 'task_arousal_score', 'task_event_type', 'task_time', 'task_monotonic_time', 'task_human_readable_time', 'task_subject_id', 'seconds_since_start', 'human_readable_time', imac, 'task_index', 'experiment_id'], inplace=True)\n",
    "if 'task_Unnamed: 0' in df.columns:\n",
    "    df.drop(columns='task_Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'unix_time' column to datetime\n",
    "# df['unix_time'] = pd.to_datetime(df['unix_time'], unit='s')\n",
    "df.dropna(inplace=True)\n",
    "# Convert the DataFrame to MNE Raw object\n",
    "raw = mne.io.RawArray(df.T.values[1:], info=mne.create_info(ch_names=df.columns[1:].to_list(), sfreq=1/(df['unix_time'].diff().mean().total_seconds()),\n",
    "                                                              ch_types=['eeg']*len(df.columns[1:])), verbose=False)\n",
    "\n",
    "sfreq = 500\n",
    "\n",
    "# Specify the desired sampling rate after downsampling\n",
    "new_sampling_rate = 100  # New sampling rate in Hz\n",
    "\n",
    "# Downsample the data\n",
    "raw_resampled = raw.resample(new_sampling_rate)\n",
    "\n",
    "# Before downsampling\n",
    "unix_times = df['unix_time'].values\n",
    "\n",
    "# After downsampling\n",
    "downsample_ratio = int(sfreq / new_sampling_rate)\n",
    "downsampled_unix_times = unix_times[::downsample_ratio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17820, (23, 17820))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(downsampled_unix_times), raw_resampled.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89100, 24)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean time difference between consecutive unix_time values\n",
    "mean_time_diff = df['unix_time'].diff().mean().total_seconds()\n",
    "\n",
    "# Specify the desired new sampling rate after downsampling\n",
    "new_sampling_rate = 100  # New sampling rate in Hz\n",
    "\n",
    "# Calculate the downsampling factor\n",
    "downsampling_factor = int(1 / (new_sampling_rate * mean_time_diff))\n",
    "\n",
    "# Downsample the EEG data\n",
    "downsampled_data = df.iloc[::downsampling_factor]\n",
    "\n",
    "# Downsample the unix_time column\n",
    "downsampled_unix_time = df['unix_time'].iloc[::downsampling_factor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unix_time</th>\n",
       "      <th>leopard_AFF1h</th>\n",
       "      <th>leopard_F7</th>\n",
       "      <th>leopard_FC5</th>\n",
       "      <th>leopard_C3</th>\n",
       "      <th>leopard_T7</th>\n",
       "      <th>leopard_TP9</th>\n",
       "      <th>leopard_Pz</th>\n",
       "      <th>leopard_P3</th>\n",
       "      <th>leopard_P7</th>\n",
       "      <th>...</th>\n",
       "      <th>leopard_TP10</th>\n",
       "      <th>leopard_Cz</th>\n",
       "      <th>leopard_C4</th>\n",
       "      <th>leopard_T8</th>\n",
       "      <th>leopard_FC6</th>\n",
       "      <th>leopard_FCz</th>\n",
       "      <th>leopard_F8</th>\n",
       "      <th>leopard_AFF2h</th>\n",
       "      <th>leopard_AUX_GSR</th>\n",
       "      <th>leopard_AUX_EKG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-04 18:16:40.677009152</td>\n",
       "      <td>0.015914</td>\n",
       "      <td>-0.011380</td>\n",
       "      <td>0.008687</td>\n",
       "      <td>0.008589</td>\n",
       "      <td>-0.014979</td>\n",
       "      <td>0.011379</td>\n",
       "      <td>0.007745</td>\n",
       "      <td>0.011237</td>\n",
       "      <td>0.013657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012609</td>\n",
       "      <td>0.017386</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.011365</td>\n",
       "      <td>0.022363</td>\n",
       "      <td>0.009064</td>\n",
       "      <td>0.011718</td>\n",
       "      <td>-0.356466</td>\n",
       "      <td>0.057533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-10-04 18:16:40.687009792</td>\n",
       "      <td>0.018926</td>\n",
       "      <td>-0.008364</td>\n",
       "      <td>0.011702</td>\n",
       "      <td>0.011599</td>\n",
       "      <td>-0.011972</td>\n",
       "      <td>0.014389</td>\n",
       "      <td>0.010744</td>\n",
       "      <td>0.014244</td>\n",
       "      <td>0.016665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015631</td>\n",
       "      <td>0.020385</td>\n",
       "      <td>0.013049</td>\n",
       "      <td>0.009267</td>\n",
       "      <td>0.014381</td>\n",
       "      <td>0.025368</td>\n",
       "      <td>0.012104</td>\n",
       "      <td>0.014726</td>\n",
       "      <td>-0.092487</td>\n",
       "      <td>0.058417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022-10-04 18:16:40.697010432</td>\n",
       "      <td>0.017012</td>\n",
       "      <td>-0.010279</td>\n",
       "      <td>0.009790</td>\n",
       "      <td>0.009687</td>\n",
       "      <td>-0.013884</td>\n",
       "      <td>0.012489</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.012342</td>\n",
       "      <td>0.014766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013702</td>\n",
       "      <td>0.018484</td>\n",
       "      <td>0.011149</td>\n",
       "      <td>0.007362</td>\n",
       "      <td>0.012477</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>0.010158</td>\n",
       "      <td>0.012820</td>\n",
       "      <td>-0.158780</td>\n",
       "      <td>0.057018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022-10-04 18:16:40.707010816</td>\n",
       "      <td>0.012932</td>\n",
       "      <td>-0.014368</td>\n",
       "      <td>0.005701</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>-0.017977</td>\n",
       "      <td>0.008366</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>0.008256</td>\n",
       "      <td>0.010655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009616</td>\n",
       "      <td>0.014411</td>\n",
       "      <td>0.007066</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>0.008389</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.006113</td>\n",
       "      <td>0.008744</td>\n",
       "      <td>-0.233194</td>\n",
       "      <td>0.058511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2022-10-04 18:16:40.717011200</td>\n",
       "      <td>0.012278</td>\n",
       "      <td>-0.015031</td>\n",
       "      <td>0.005041</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>-0.018648</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>0.007590</td>\n",
       "      <td>0.009988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008943</td>\n",
       "      <td>0.013753</td>\n",
       "      <td>0.006396</td>\n",
       "      <td>0.002595</td>\n",
       "      <td>0.007719</td>\n",
       "      <td>0.018724</td>\n",
       "      <td>0.005414</td>\n",
       "      <td>0.008084</td>\n",
       "      <td>0.012998</td>\n",
       "      <td>0.056775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89087</th>\n",
       "      <td>2022-10-04 18:19:38.857335040</td>\n",
       "      <td>0.017070</td>\n",
       "      <td>-0.010044</td>\n",
       "      <td>0.009765</td>\n",
       "      <td>0.009555</td>\n",
       "      <td>-0.013778</td>\n",
       "      <td>0.012521</td>\n",
       "      <td>0.008778</td>\n",
       "      <td>0.012267</td>\n",
       "      <td>0.014683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013703</td>\n",
       "      <td>0.018499</td>\n",
       "      <td>0.011129</td>\n",
       "      <td>0.007221</td>\n",
       "      <td>0.012467</td>\n",
       "      <td>0.023662</td>\n",
       "      <td>0.010141</td>\n",
       "      <td>0.012730</td>\n",
       "      <td>0.014982</td>\n",
       "      <td>0.058009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89092</th>\n",
       "      <td>2022-10-04 18:19:38.867335680</td>\n",
       "      <td>0.013693</td>\n",
       "      <td>-0.013424</td>\n",
       "      <td>0.006390</td>\n",
       "      <td>0.006178</td>\n",
       "      <td>-0.017163</td>\n",
       "      <td>0.009145</td>\n",
       "      <td>0.005413</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.011298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010313</td>\n",
       "      <td>0.015132</td>\n",
       "      <td>0.007748</td>\n",
       "      <td>0.003837</td>\n",
       "      <td>0.009080</td>\n",
       "      <td>0.020285</td>\n",
       "      <td>0.006728</td>\n",
       "      <td>0.009356</td>\n",
       "      <td>-0.154783</td>\n",
       "      <td>0.056983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89097</th>\n",
       "      <td>2022-10-04 18:19:38.877336576</td>\n",
       "      <td>0.014111</td>\n",
       "      <td>-0.013010</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>-0.016750</td>\n",
       "      <td>0.009552</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>0.009298</td>\n",
       "      <td>0.011718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010727</td>\n",
       "      <td>0.015544</td>\n",
       "      <td>0.008159</td>\n",
       "      <td>0.004252</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.020701</td>\n",
       "      <td>0.007155</td>\n",
       "      <td>0.009770</td>\n",
       "      <td>-0.124649</td>\n",
       "      <td>0.058420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89102</th>\n",
       "      <td>2022-10-04 18:19:38.887336704</td>\n",
       "      <td>0.017884</td>\n",
       "      <td>-0.009230</td>\n",
       "      <td>0.010576</td>\n",
       "      <td>0.010362</td>\n",
       "      <td>-0.012988</td>\n",
       "      <td>0.013326</td>\n",
       "      <td>0.009578</td>\n",
       "      <td>0.013063</td>\n",
       "      <td>0.015485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.019305</td>\n",
       "      <td>0.011929</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>0.013266</td>\n",
       "      <td>0.024472</td>\n",
       "      <td>0.010937</td>\n",
       "      <td>0.013538</td>\n",
       "      <td>-0.032252</td>\n",
       "      <td>0.056823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89107</th>\n",
       "      <td>2022-10-04 18:19:38.897337088</td>\n",
       "      <td>0.019530</td>\n",
       "      <td>-0.007593</td>\n",
       "      <td>0.012218</td>\n",
       "      <td>0.012005</td>\n",
       "      <td>-0.011322</td>\n",
       "      <td>0.014979</td>\n",
       "      <td>0.011223</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.017137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016157</td>\n",
       "      <td>0.020951</td>\n",
       "      <td>0.013581</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>0.014916</td>\n",
       "      <td>0.026121</td>\n",
       "      <td>0.012557</td>\n",
       "      <td>0.015187</td>\n",
       "      <td>-0.246833</td>\n",
       "      <td>0.058447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17820 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          unix_time  leopard_AFF1h  leopard_F7  leopard_FC5   \n",
       "1     2022-10-04 18:16:40.677009152       0.015914   -0.011380     0.008687  \\\n",
       "6     2022-10-04 18:16:40.687009792       0.018926   -0.008364     0.011702   \n",
       "11    2022-10-04 18:16:40.697010432       0.017012   -0.010279     0.009790   \n",
       "16    2022-10-04 18:16:40.707010816       0.012932   -0.014368     0.005701   \n",
       "21    2022-10-04 18:16:40.717011200       0.012278   -0.015031     0.005041   \n",
       "...                             ...            ...         ...          ...   \n",
       "89087 2022-10-04 18:19:38.857335040       0.017070   -0.010044     0.009765   \n",
       "89092 2022-10-04 18:19:38.867335680       0.013693   -0.013424     0.006390   \n",
       "89097 2022-10-04 18:19:38.877336576       0.014111   -0.013010     0.006800   \n",
       "89102 2022-10-04 18:19:38.887336704       0.017884   -0.009230     0.010576   \n",
       "89107 2022-10-04 18:19:38.897337088       0.019530   -0.007593     0.012218   \n",
       "\n",
       "       leopard_C3  leopard_T7  leopard_TP9  leopard_Pz  leopard_P3   \n",
       "1        0.008589   -0.014979     0.011379    0.007745    0.011237  \\\n",
       "6        0.011599   -0.011972     0.014389    0.010744    0.014244   \n",
       "11       0.009687   -0.013884     0.012489    0.008850    0.012342   \n",
       "16       0.005600   -0.017977     0.008366    0.004782    0.008256   \n",
       "21       0.004940   -0.018648     0.007700    0.004123    0.007590   \n",
       "...           ...         ...          ...         ...         ...   \n",
       "89087    0.009555   -0.013778     0.012521    0.008778    0.012267   \n",
       "89092    0.006178   -0.017163     0.009145    0.005413    0.008889   \n",
       "89097    0.006593   -0.016750     0.009552    0.005824    0.009298   \n",
       "89102    0.010362   -0.012988     0.013326    0.009578    0.013063   \n",
       "89107    0.012005   -0.011322     0.014979    0.011223    0.014712   \n",
       "\n",
       "       leopard_P7  ...  leopard_TP10  leopard_Cz  leopard_C4  leopard_T8   \n",
       "1        0.013657  ...      0.012609    0.017386    0.010032    0.006250  \\\n",
       "6        0.016665  ...      0.015631    0.020385    0.013049    0.009267   \n",
       "11       0.014766  ...      0.013702    0.018484    0.011149    0.007362   \n",
       "16       0.010655  ...      0.009616    0.014411    0.007066    0.003271   \n",
       "21       0.009988  ...      0.008943    0.013753    0.006396    0.002595   \n",
       "...           ...  ...           ...         ...         ...         ...   \n",
       "89087    0.014683  ...      0.013703    0.018499    0.011129    0.007221   \n",
       "89092    0.011298  ...      0.010313    0.015132    0.007748    0.003837   \n",
       "89097    0.011718  ...      0.010727    0.015544    0.008159    0.004252   \n",
       "89102    0.015485  ...      0.014500    0.019305    0.011929    0.008019   \n",
       "89107    0.017137  ...      0.016157    0.020951    0.013581    0.009677   \n",
       "\n",
       "       leopard_FC6  leopard_FCz  leopard_F8  leopard_AFF2h  leopard_AUX_GSR   \n",
       "1         0.011365     0.022363    0.009064       0.011718        -0.356466  \\\n",
       "6         0.014381     0.025368    0.012104       0.014726        -0.092487   \n",
       "11        0.012477     0.023460    0.010158       0.012820        -0.158780   \n",
       "16        0.008389     0.019380    0.006113       0.008744        -0.233194   \n",
       "21        0.007719     0.018724    0.005414       0.008084         0.012998   \n",
       "...            ...          ...         ...            ...              ...   \n",
       "89087     0.012467     0.023662    0.010141       0.012730         0.014982   \n",
       "89092     0.009080     0.020285    0.006728       0.009356        -0.154783   \n",
       "89097     0.009497     0.020701    0.007155       0.009770        -0.124649   \n",
       "89102     0.013266     0.024472    0.010937       0.013538        -0.032252   \n",
       "89107     0.014916     0.026121    0.012557       0.015187        -0.246833   \n",
       "\n",
       "       leopard_AUX_EKG  \n",
       "1             0.057533  \n",
       "6             0.058417  \n",
       "11            0.057018  \n",
       "16            0.058511  \n",
       "21            0.056775  \n",
       "...                ...  \n",
       "89087         0.058009  \n",
       "89092         0.056983  \n",
       "89097         0.058420  \n",
       "89102         0.056823  \n",
       "89107         0.058447  \n",
       "\n",
       "[17820 rows x 24 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       2022-10-04 18:16:40.677009152\n",
       "6       2022-10-04 18:16:40.687009792\n",
       "11      2022-10-04 18:16:40.697010432\n",
       "16      2022-10-04 18:16:40.707010816\n",
       "21      2022-10-04 18:16:40.717011200\n",
       "                     ...             \n",
       "89087   2022-10-04 18:19:38.857335040\n",
       "89092   2022-10-04 18:19:38.867335680\n",
       "89097   2022-10-04 18:19:38.877336576\n",
       "89102   2022-10-04 18:19:38.887336704\n",
       "89107   2022-10-04 18:19:38.897337088\n",
       "Name: unix_time, Length: 17820, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsampled_unix_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
